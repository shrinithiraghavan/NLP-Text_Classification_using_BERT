{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdgL25ohQnvP",
    "outputId": "aedb7a62-a21f-4bb8-aa8b-61b42b281bc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-B18vA8NRnMk",
    "outputId": "6c5eac32-b6ea-417c-8ac0-a07dd8e9c495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers~=3.5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 15.3MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.9.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 46.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers~=3.5.1) (4.41.1)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 46.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers~=3.5.1) (3.12.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers~=3.5.1) (1.18.5)\n",
      "Collecting sentencepiece==0.1.91\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 48.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers~=3.5.1) (0.8)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers~=3.5.1) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers~=3.5.1) (20.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers~=3.5.1) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers~=3.5.1) (2019.12.20)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers~=3.5.1) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers~=3.5.1) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers~=3.5.1) (0.17.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers~=3.5.1) (50.3.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=3.5.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=3.5.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=3.5.1) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=3.5.1) (1.24.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers~=3.5.1) (2.4.7)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c25e3de7a1c2ca335c34748d5aed17b91d0fd34fc28213c61d47e7c1783a4b90\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers~=3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeH71U85ScZY",
    "outputId": "f09cd4fc-36c2-44f9-e532-9852ba1a6964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import torchtext.data as ttd\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.optim.lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "import gensim \n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec  \n",
    "#from torchnlp.word_to_vector import GloVe, FastText\n",
    "import torchtext.data as ttd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer, word_tokenize, sent_tokenize, TweetTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,HashingVectorizer\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from warnings import simplefilter\n",
    "#simplefilter(action='ignore', category=FutureWarning)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from transformers import BertTokenizer\n",
    "import transformers as tran\n",
    "\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from torch.utils.data import TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hC-kmib2RnKz"
   },
   "outputs": [],
   "source": [
    "folder=Path('/content/gdrive/My Drive/NLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zrRLdaNFRnIB",
    "outputId": "c8e02ad6-c6d0-4723-9f93-78bcb552b0d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "4N49v5jme8Cj",
    "outputId": "fce2fee5-aede-4cb1-a365-c35414da9d5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11210</th>\n",
       "      <td>Secrecy in Clipper Chip\\n\\nThe serial number o...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11217</th>\n",
       "      <td>Hi !\\n\\nI am interested in the source of FEAL ...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11243</th>\n",
       "      <td>The actual algorithm is classified, however, t...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11254</th>\n",
       "      <td>\\n\\tThis appears to be generic calling upon th...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11302</th>\n",
       "      <td>\\nProbably keep quiet and take it, lest they g...</td>\n",
       "      <td>11</td>\n",
       "      <td>sci.crypt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text target      title\n",
       "0      I was wondering if anyone out there could enli...      7  rec.autos\n",
       "17     I recently posted an article asking what kind ...      7  rec.autos\n",
       "29     \\nIt depends on your priorities.  A lot of peo...      7  rec.autos\n",
       "56     an excellent automatic can be found in the sub...      7  rec.autos\n",
       "64     : Ford and his automobile.  I need information...      7  rec.autos\n",
       "...                                                  ...    ...        ...\n",
       "11210  Secrecy in Clipper Chip\\n\\nThe serial number o...     11  sci.crypt\n",
       "11217  Hi !\\n\\nI am interested in the source of FEAL ...     11  sci.crypt\n",
       "11243  The actual algorithm is classified, however, t...     11  sci.crypt\n",
       "11254  \\n\\tThis appears to be generic calling upon th...     11  sci.crypt\n",
       "11302  \\nProbably keep quiet and take it, lest they g...     11  sci.crypt\n",
       "\n",
       "[11314 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame([train.data, train.target.tolist()]).T\n",
    "df1.columns = ['text', 'target']\n",
    "\n",
    "targets = pd.DataFrame( train.target_names)\n",
    "targets.columns=['title']\n",
    "\n",
    "df_train = pd.merge(df1, targets, left_on='target', right_index=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "WLhlv0Scfaw1",
    "outputId": "05a981db-b6ff-48cf-d444-46ace7796403"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a little confused on all of the models of...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I have a 90 Eagle Talon and I wanted a pair of...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hi,\\nI need your help with a problem I have wi...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>\\nThey changed the lights and slope of the hoo...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>I am thinking of buying a used Audi 90 Auto.\\n...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7426</th>\n",
       "      <td>\\nI think it's because the lead gets coated wi...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>\\n\\nWith regards to what you wrote, how does ...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7507</th>\n",
       "      <td>\\nWhy can't he record it legally?  It may not ...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7510</th>\n",
       "      <td>\\n\\n\\nIt sorta depends on what you drive. I re...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>Can anyone point me to a cross compiler and/or...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7532 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text target            title\n",
       "0     I am a little confused on all of the models of...      7        rec.autos\n",
       "27    I have a 90 Eagle Talon and I wanted a pair of...      7        rec.autos\n",
       "28    Hi,\\nI need your help with a problem I have wi...      7        rec.autos\n",
       "75    \\nThey changed the lights and slope of the hoo...      7        rec.autos\n",
       "77    I am thinking of buying a used Audi 90 Auto.\\n...      7        rec.autos\n",
       "...                                                 ...    ...              ...\n",
       "7426  \\nI think it's because the lead gets coated wi...     12  sci.electronics\n",
       "7445   \\n\\nWith regards to what you wrote, how does ...     12  sci.electronics\n",
       "7507  \\nWhy can't he record it legally?  It may not ...     12  sci.electronics\n",
       "7510  \\n\\n\\nIt sorta depends on what you drive. I re...     12  sci.electronics\n",
       "7519  Can anyone point me to a cross compiler and/or...     12  sci.electronics\n",
       "\n",
       "[7532 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame([test.data, test.target.tolist()]).T\n",
    "df2.columns = ['text', 'target']\n",
    "\n",
    "targets1 = pd.DataFrame( test.target_names)\n",
    "targets1.columns=['title']\n",
    "\n",
    "df_test = pd.merge(df2, targets1, left_on='target', right_index=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_6JCYzpRm5z",
    "outputId": "b13f5249-4f00-45ac-c497-0275fd8efb2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos' 'rec.autos' 'rec.autos' ... 'sci.crypt' 'sci.crypt'\n",
      " 'sci.crypt']\n"
     ]
    }
   ],
   "source": [
    "print(df_train.title.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8NY9lJPf8B_",
    "outputId": "ffece3d5-6037-47d7-d6e8-6d43ab41d15a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method IndexOpsMixin.value_counts of 0        rec.autos\n",
      "17       rec.autos\n",
      "29       rec.autos\n",
      "56       rec.autos\n",
      "64       rec.autos\n",
      "           ...    \n",
      "11210    sci.crypt\n",
      "11217    sci.crypt\n",
      "11243    sci.crypt\n",
      "11254    sci.crypt\n",
      "11302    sci.crypt\n",
      "Name: title, Length: 11314, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "print(df_train.title.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "lYxNegClZ9nP",
    "outputId": "ce81e304-4c2b-44c8-905e-b0ca1b9fc66b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the number of tokens of each length.\n",
    "sns.countplot(train.target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165,
     "referenced_widgets": [
      "a681dc57ca744c5bb424e4488d07c889",
      "8b6dd75fb9444bd7ad88d6910e4b4bd4",
      "1694fc120faa4a30860733d5b0ca8533",
      "d6a6c9ff713348d9a813fbd4f0cbc3df",
      "aab857b501084bf488961ccf31924bee",
      "3eedd8bb2d854cf388946a1fc0d63577",
      "b618944566424a6e9f3d5dd229a06845",
      "f07be0e793c4447aba164b6ca1112af5",
      "f990b63899de4008b7c80fb8f8edf674",
      "19d4206ea1df44e7954c92d7c648324a",
      "c8724715e9a3449dae16956c0be83bfb",
      "4367fa1db43445aea120b5a1fcee4f2a",
      "ac07937a5185429d842716f37a780347",
      "08c203665d564f5484aff36928672cad",
      "5dcf3052e7c34415bf04c6e4d7b8ac29",
      "457256a41d4f4380acd38eb90f9e311a",
      "376bf49ee5ad41ddb8cf28e679179210",
      "ada1ba9c9b38401da7bbef43046962bc",
      "85b1e13a986b4a81ae39ede39c326719",
      "2ff16d02cd5a49c494ec6d25bb33dd1c",
      "e1d6fc436e6a43c4a8d5976463d9bd1d",
      "794babb404914bd199182f8215637674",
      "9f3d0086e0534ffd8412795996d75f5b",
      "9a089271081b4497862c48550e0c516c"
     ]
    },
    "id": "veNgfqNEZ9j6",
    "outputId": "a8b61537-b08c-443f-cb10-88bdfbb9dcd6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a681dc57ca744c5bb424e4488d07c889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f990b63899de4008b7c80fb8f8edf674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376bf49ee5ad41ddb8cf28e679179210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (tran.BertModel, tran.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFlTe9BiNAR_"
   },
   "source": [
    "**1. a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4oEJu9Ea9lXI"
   },
   "outputs": [],
   "source": [
    "tokens = df_train['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512,truncation= True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "s1rUqVse9lOi"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokens.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokens.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-sFZpQu9lL1",
    "outputId": "044890d8-6528-4bfc-ef62-09e4598a42d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUFAllxI9lJj",
    "outputId": "912b4d8f-d1ae-4aaa-df07-9da0202bd706"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 512)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_msk = np.where(padded != 0, 1, 0)\n",
    "attn_msk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "N_gm1xUZ-TL0"
   },
   "outputs": [],
   "source": [
    "input = torch.tensor(padded) \n",
    "attention_mask = torch.tensor(attn_msk)\n",
    "\n",
    "target=torch.tensor(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCu7C7_K-TJT",
    "outputId": "32b481d0-0c21-4b8f-9e99-4e8de58a3755"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11314])"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DhhTp1L4-THA"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input, attention_mask, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "s-a94mLVAVAS"
   },
   "outputs": [],
   "source": [
    "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                        batch_size=16,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pRdIrWjAU-X",
    "outputId": "d125a0d1-e67d-4b54-a476-854b3b38123f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0XqHeZaAU7E",
    "outputId": "b9a87498-c754-47e9-fd0e-669a86ff3782"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VD_VoeJS9lBk",
    "outputId": "bdeda1b9-65b6-443f-d49d-c5fbde9926d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vpyVX3o9CGDM"
   },
   "outputs": [],
   "source": [
    " for i, (input,attention_mask, target) in enumerate(data_loader):\n",
    "   input=input.to(device)\n",
    "   attention_mask=attention_mask.to(device)\n",
    "   target=target.to(device)\n",
    "\n",
    "   with torch.no_grad():\n",
    "    final_hidden_state = model(input, attention_mask=attention_mask)[0][:,0,:]\n",
    "      \n",
    "    if i==0:\n",
    "        All_final_hidden_state = final_hidden_state\n",
    "        All_target= target\n",
    "\n",
    "    else:\n",
    "        All_final_hidden_state=torch.cat((All_final_hidden_state,final_hidden_state),axis=0)\n",
    "        All_target=torch.cat((All_target,target),axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8R8YMykCGBo",
    "outputId": "ff2be449-0e86-4477-da31-47745f6f45fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11314, 768])\n",
      "torch.Size([11314])\n",
      "(11314, 768)\n",
      "(11314,)\n"
     ]
    }
   ],
   "source": [
    "print(All_final_hidden_state.shape)\n",
    "print(All_target.shape)\n",
    "\n",
    "#We'll save those in the features variable, as they'll serve as the features to our logitics regression model.\n",
    "features = All_final_hidden_state.cpu().numpy()\n",
    "print(features.shape)\n",
    "\n",
    "target = All_target.cpu().numpy()\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6NOOCLJG7RI"
   },
   "source": [
    "**Splitting Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "uRZkgo7fCF-R"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PR-HyvgmCF7g",
    "outputId": "f45f2b7d-f533-411b-91ec-c582ead97bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.1}\n",
      "best scrores:  0.6497348261638185\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters = {'C': [0.001,0.01,0.1,1]}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "print('best parameters: ', grid_search.best_params_)\n",
    "print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLZyJ7PHCF5F",
    "outputId": "fc4bdd8f-701a-4b33-cedf-03173c6fe8ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "DERgngLDCF2a"
   },
   "outputs": [],
   "source": [
    "test = LogisticRegression(max_iter=10000, C= 0.1)\n",
    "test.fit(train_features, train_labels)\n",
    "\n",
    "y_pred = test.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8f2IrjLCFzY",
    "outputId": "8144555b-739b-42bc-d228-73b2aee8bd46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.6667\n"
     ]
    }
   ],
   "source": [
    "print('Test score: {:.4f}'.format(accuracy_score(test_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcdAOPnANQDj"
   },
   "source": [
    "**1. b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ZGhIMV4nLWrT"
   },
   "outputs": [],
   "source": [
    "tokens = df_train['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=128,truncation= True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "2CMscA9QLWpi"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokens.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokens.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWvwCFAHLWms",
    "outputId": "3f5ab8b3-f2e9-400d-a75e-a7a658609f02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 128)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpeEwESELWiI",
    "outputId": "e37026c2-638d-4676-910a-46ec1215edb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 128)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_msk = np.where(padded != 0, 1, 0)\n",
    "attn_msk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "tsEUlwHPCFnK"
   },
   "outputs": [],
   "source": [
    "input = torch.tensor(padded) \n",
    "attention_mask = torch.tensor(attn_msk)\n",
    "\n",
    "target=torch.tensor(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNln0cFXNuVC",
    "outputId": "c0cf995c-934e-4ba2-fc81-b71e207edf25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11314])"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "wGeTU2U-NuTD"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input, attention_mask, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ei2AYLhGNuQu"
   },
   "outputs": [],
   "source": [
    "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                        batch_size=16,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7D8lJuUWNuPI",
    "outputId": "aae93e5f-ce4b-40e0-a2d7-bd79a4a2e062"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMIOzoD2NuLF",
    "outputId": "2b1e9c4c-99ed-40b8-848e-6fe2fc5c3648"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5ouNEzBOfZr",
    "outputId": "3a1e3818-e5ee-4b4a-e83e-5b4deb0f5805"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "M1diF4DvOfXn"
   },
   "outputs": [],
   "source": [
    " for i, (input,attention_mask, target) in enumerate(data_loader):\n",
    "   input=input.to(device)\n",
    "   attention_mask=attention_mask.to(device)\n",
    "   target=target.to(device)\n",
    "\n",
    "   with torch.no_grad():\n",
    "    final_hidden_state = model(input, attention_mask=attention_mask)[0][:,0,:]\n",
    "      \n",
    "    if i==0:\n",
    "        All_final_hidden_state = final_hidden_state\n",
    "        All_target= target\n",
    "\n",
    "    else:\n",
    "        All_final_hidden_state=torch.cat((All_final_hidden_state,final_hidden_state),axis=0)\n",
    "        All_target=torch.cat((All_target,target),axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2AnghFfOOfVR",
    "outputId": "34fa254c-eb5f-44de-c220-1d2e13071017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11314, 768])\n",
      "torch.Size([11314])\n",
      "(11314, 768)\n",
      "(11314,)\n"
     ]
    }
   ],
   "source": [
    "print(All_final_hidden_state.shape)\n",
    "print(All_target.shape)\n",
    "\n",
    "#We'll save those in the features variable, as they'll serve as the features to our logitics regression model.\n",
    "features = All_final_hidden_state.cpu().numpy()\n",
    "print(features.shape)\n",
    "\n",
    "target = All_target.cpu().numpy()\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCt7MgXfOxK4"
   },
   "source": [
    "**Splitting train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "0zD04XpMOfTi"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7pUhTeWOfR4",
    "outputId": "6501cbc0-f4eb-4422-e946-0e4a52bcf23d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.1}\n",
      "best scrores:  0.6360636417206835\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters = {'C': [0.001,0.01,0.1,1]}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "print('best parameters: ', grid_search.best_params_)\n",
    "print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFpJ0x9UOfQD",
    "outputId": "d8abe3d4-4967-40ab-cfd0-0e7d34abf1b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6514669494521033"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "spDDF3g4OfL-"
   },
   "outputs": [],
   "source": [
    "test = LogisticRegression(max_iter=10000, C= 0.1)\n",
    "test.fit(train_features, train_labels)\n",
    "\n",
    "y_pred = test.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ld21TVPqPGpv",
    "outputId": "fb2da1b8-1441-43b2-9710-49c97897554e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.6515\n"
     ]
    }
   ],
   "source": [
    "print('Test score: {:.4f}'.format(accuracy_score(test_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YckB98YLPOMO"
   },
   "source": [
    "**1. c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "wM9jW-vGPGk3"
   },
   "outputs": [],
   "source": [
    "tokens = df_train['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=140,truncation= True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "G0V_DQG0PGjS"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokens.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokens.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnT-CTprPGhr",
    "outputId": "49b6a9d1-c432-4b59-f4d8-1419c5dabae2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 140)"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfwunfZaPGd-",
    "outputId": "f03bf807-934c-4f5d-e6aa-0d5df67b589c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 140)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_msk = np.where(padded != 0, 1, 0)\n",
    "attn_msk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "P2o7shpHPGcH"
   },
   "outputs": [],
   "source": [
    "input = torch.tensor(padded) \n",
    "attention_mask = torch.tensor(attn_msk)\n",
    "\n",
    "target=torch.tensor(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRYc1VFZPGaT",
    "outputId": "ef54277a-84b2-4f4f-c380-9c629158aa9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11314])"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "EnnIGphCPGU4"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input, attention_mask, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "9qlWdSsZPsOp"
   },
   "outputs": [],
   "source": [
    "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                        batch_size=16,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6jHEs7dPsJ1",
    "outputId": "e886c502-0b50-4e50-8d0f-9ec8cc3f0d51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLQ8P7p_PsGw",
    "outputId": "de682828-fc45-4929-851c-1a4f0c93a162"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkpRQDiVPsEs",
    "outputId": "0412e145-ab8a-48db-f1ed-8d563a60680c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "CPN2xytjPsDK"
   },
   "outputs": [],
   "source": [
    " for i, (input,attention_mask, target) in enumerate(data_loader):\n",
    "   input=input.to(device)\n",
    "   attention_mask=attention_mask.to(device)\n",
    "   target=target.to(device)\n",
    "\n",
    "   with torch.no_grad():\n",
    "    final_hidden_state = model(input, attention_mask=attention_mask)[0][:,0,:]\n",
    "      \n",
    "    if i==0:\n",
    "        All_final_hidden_state = final_hidden_state\n",
    "        All_target= target\n",
    "\n",
    "    else:\n",
    "        All_final_hidden_state=torch.cat((All_final_hidden_state,final_hidden_state),axis=0)\n",
    "        All_target=torch.cat((All_target,target),axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPjUAZKyPr-_",
    "outputId": "b7ff4c92-a5fa-4825-c83e-9b8178d608a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11314, 768])\n",
      "torch.Size([11314])\n",
      "(11314, 768)\n",
      "(11314,)\n"
     ]
    }
   ],
   "source": [
    "print(All_final_hidden_state.shape)\n",
    "print(All_target.shape)\n",
    "\n",
    "#We'll save those in the features variable, as they'll serve as the features to our logitics regression model.\n",
    "features = All_final_hidden_state.cpu().numpy()\n",
    "print(features.shape)\n",
    "\n",
    "target = All_target.cpu().numpy()\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s--Y3f57QFWi"
   },
   "source": [
    "**Splitting train and test** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "s-wsNRVyPr6A"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nsJwPB1zQKqw",
    "outputId": "d85d939e-ffcc-4f8f-863c-b1908c1cf967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.1}\n",
      "best scrores:  0.6324101355332941\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parameters = {'C': [0.001,0.01,0.1,1]}\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "print('best parameters: ', grid_search.best_params_)\n",
    "print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_nk3lkWQKoM",
    "outputId": "b000d28d-9d92-4843-8ae5-c81b07812dc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6359137504418523"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "JHcNqTiFQKlw"
   },
   "outputs": [],
   "source": [
    "test = LogisticRegression(max_iter=10000, C= 0.1)\n",
    "test.fit(train_features, train_labels)\n",
    "\n",
    "y_pred = test.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKH6mMqdQKjq",
    "outputId": "f4c4e5af-2774-415b-e321-0b2a301aa311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.6359\n"
     ]
    }
   ],
   "source": [
    "print('Test score: {:.4f}'.format(accuracy_score(test_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDrVnmigWhg9"
   },
   "source": [
    "**1. d)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEzg3XwGWfuh"
   },
   "outputs": [],
   "source": [
    "# 1) 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EP2RbtVipPrj",
    "outputId": "d08c9e17-c064-4d5a-9760-141f0ee7a6b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3226 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "decoder_sent=[]\n",
    "before_trunc=[]\n",
    "maxlen=512\n",
    "\n",
    "for sent in df_train.text:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                     \n",
    "                        add_special_tokens = True, \n",
    "                        truncation=False,\n",
    "                        padding=False,\n",
    "                        return_attention_mask = True\n",
    "                   )\n",
    "   \n",
    "    before_trunc.append(encoded_dict['input_ids'])\n",
    "\n",
    "    ids = encoded_dict['input_ids']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [102]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['input_ids']=torch.tensor([ids])\n",
    "\n",
    "    ids = encoded_dict['attention_mask']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
    " \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    #print(input_ids)\n",
    "        \n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    decoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "o6iDTpHgpPoQ"
   },
   "outputs": [],
   "source": [
    "labels=torch.tensor(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "kivMZYfCpPkz"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                        batch_size=256,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZmp86vlpPhD",
    "outputId": "a5ef50a9-bfb1-4e4a-992d-f002f66d1218"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "3hw9Pad_pPap"
   },
   "outputs": [],
   "source": [
    "\n",
    " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
    "   input_ids=input_ids.to(device)\n",
    "   attention_mask=attention_mask.to(device)\n",
    "   labels=labels.to(device)\n",
    "   with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
    "      \n",
    "    if i==0:\n",
    "        last_hidden_states_all = last_hidden_states\n",
    "        labels_all= labels\n",
    "    else:\n",
    "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
    "        labels_all=torch.cat((labels_all,labels),axis=0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsUnDutspPWO",
    "outputId": "64ffb862-ce7f-470b-f0b2-03b2caccb5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11314, 768])\n",
      "torch.Size([11314])\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_states_all.shape)\n",
    "print(labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GLhrEj2EpPSq",
    "outputId": "101e682d-decd-4aeb-9396-c67eb73b2a55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 768)"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = last_hidden_states_all.cpu().numpy()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "teAT8mSEpPOn",
    "outputId": "5fc1de72-5f89-41d9-cfc2-16f676cd31e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels_all.cpu().numpy()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcRGhqV2xo5n"
   },
   "source": [
    "**Splitting Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "UmgfouaypPLN"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNjy7AnWpPIB",
    "outputId": "0caf1ebf-189d-4b60-fb26-099c3e428785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.1}\n",
      "best scrores:  0.6513847967000589\n"
     ]
    }
   ],
   "source": [
    " parameters = {'C': [0.001,0.01,0.1,1]}\n",
    " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
    " grid_search.fit(train_features, train_labels)\n",
    "\n",
    " print('best parameters: ', grid_search.best_params_)\n",
    " print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzfOIHh0pPE8",
    "outputId": "b3eadd7a-6084-45cc-efed-b78e9ff0341d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648639095086603"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HK-eDeZpPBa"
   },
   "outputs": [],
   "source": [
    "# 2) 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "FrrneZZZyCZY"
   },
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "decoder_sent=[]\n",
    "before_trunc=[]\n",
    "maxlen=128\n",
    "\n",
    "for sent in df_train.text:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                     \n",
    "                        add_special_tokens = True, \n",
    "                        truncation=False,\n",
    "                        padding=False,\n",
    "                        return_attention_mask = True\n",
    "                   )\n",
    "   \n",
    "    before_trunc.append(encoded_dict['input_ids'])\n",
    "\n",
    "    ids = encoded_dict['input_ids']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [102]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['input_ids']=torch.tensor([ids])\n",
    "\n",
    "    ids = encoded_dict['attention_mask']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
    " \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    #print(input_ids)\n",
    "        \n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    decoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "xdppOfj7yCWA"
   },
   "outputs": [],
   "source": [
    "labels=torch.tensor(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "OfBpp_TmyCSI"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                        batch_size=256,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXQRoW9jyCOg",
    "outputId": "f76d7a3b-fe51-459f-a708-96838344156d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "9hkL2iUayCKN"
   },
   "outputs": [],
   "source": [
    " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
    "   input_ids=input_ids.to(device)\n",
    "   attention_mask=attention_mask.to(device)\n",
    "   labels=labels.to(device)\n",
    "   with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
    "      \n",
    "    if i==0:\n",
    "        last_hidden_states_all = last_hidden_states\n",
    "        labels_all= labels\n",
    "    else:\n",
    "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
    "        labels_all=torch.cat((labels_all,labels),axis=0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXi-4xW5yCGm",
    "outputId": "f1dd6418-c162-4e59-bd26-623cd22e5472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11314, 768])\n",
      "torch.Size([11314])\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_states_all.shape)\n",
    "print(labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9ufBpoHyCCB",
    "outputId": "b75d6607-f6b3-44c5-ed15-40eb4f4123eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 768)"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = last_hidden_states_all.cpu().numpy()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cehqetOZyB-N",
    "outputId": "d0940162-dc1d-45ae-b526-1b4cbfe51416"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels_all.cpu().numpy()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOCElDdTzDMU"
   },
   "source": [
    "**Splitting Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "5Y9YjhURyB6Q"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNZfMPCMyB07",
    "outputId": "33bccf08-d620-4b0e-8c7a-ca52029164f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.1}\n",
      "best scrores:  0.6147318797878609\n"
     ]
    }
   ],
   "source": [
    " parameters = {'C': [0.001,0.01,0.1,1]}\n",
    " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
    " grid_search.fit(train_features, train_labels)\n",
    "\n",
    " print('best parameters: ', grid_search.best_params_)\n",
    " print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rb1emBJ8yBwq",
    "outputId": "029e38ec-e885-4fa4-b48b-e3d28e9d5ee9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6136443973135384"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5-qalRzpO8l"
   },
   "outputs": [],
   "source": [
    "# 3) 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "_b7nVxVIpO5Q"
   },
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "decoder_sent=[]\n",
    "before_trunc=[]\n",
    "maxlen=140\n",
    "\n",
    "for sent in df_train.text:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                     \n",
    "                        add_special_tokens = True, \n",
    "                        truncation=False,\n",
    "                        padding=False,\n",
    "                        return_attention_mask = True\n",
    "                   )\n",
    "   \n",
    "    before_trunc.append(encoded_dict['input_ids'])\n",
    "\n",
    "    ids = encoded_dict['input_ids']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [102]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['input_ids']=torch.tensor([ids])\n",
    "\n",
    "    ids = encoded_dict['attention_mask']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
    " \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    #print(input_ids)\n",
    "        \n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    decoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "ka3m2vX3pO1o"
   },
   "outputs": [],
   "source": [
    "labels=torch.tensor(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "d_nr9BshpOwT"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                        batch_size=256,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LJqSfEAZ9EI",
    "outputId": "8d5fbe3d-56a8-49c3-9d14-b968117ee298"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "dkvpYP7TZ9Ay"
   },
   "outputs": [],
   "source": [
    " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
    "   input_ids=input_ids.to(device)\n",
    "   attention_mask=attention_mask.to(device)\n",
    "   labels=labels.to(device)\n",
    "   with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
    "      \n",
    "    if i==0:\n",
    "        last_hidden_states_all = last_hidden_states\n",
    "        labels_all= labels\n",
    "    else:\n",
    "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
    "        labels_all=torch.cat((labels_all,labels),axis=0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "haLo2CpfzwMI",
    "outputId": "e3754dfe-4b44-4eb1-e86d-110261c63692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11314, 768])\n",
      "torch.Size([11314])\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_states_all.shape)\n",
    "print(labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ss5dd4ypzwJl",
    "outputId": "a1a4f164-45a4-4f57-a079-16f8fa068e7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 768)"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = last_hidden_states_all.cpu().numpy()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kuYvxP-zwHC",
    "outputId": "32592e11-b9ac-49b5-c7be-462c314d3721"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels_all.cpu().numpy()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvBSvIQrz6DX"
   },
   "source": [
    "**Splitting Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "0e4QNup4zwEZ"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETHgtevIzwB7",
    "outputId": "2bb31642-3059-4eda-fe2e-76dff5e0c9d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.1}\n",
      "best scrores:  0.6183853859752504\n"
     ]
    }
   ],
   "source": [
    " parameters = {'C': [0.001,0.01,0.1,1]}\n",
    " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
    " grid_search.fit(train_features, train_labels)\n",
    "\n",
    " print('best parameters: ', grid_search.best_params_)\n",
    " print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "357AqH08zv_h",
    "outputId": "8fe286c2-4578-4b39-9737-233896d457f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263697419582891"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EOKi0Yt36mkr"
   },
   "source": [
    "**1. e)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXHtfqVwzv8B"
   },
   "outputs": [],
   "source": [
    "# 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "snwtkj3hzv4V"
   },
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "decoder_sent=[]\n",
    "before_trunc=[]\n",
    "maxlen=512\n",
    "\n",
    "for sent in df_train.text:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                     \n",
    "                        add_special_tokens = True, \n",
    "                        truncation=False,\n",
    "                        padding=False,           \n",
    "                        return_attention_mask = True\n",
    "                   )\n",
    "   \n",
    "    before_trunc.append(encoded_dict['input_ids'])\n",
    "\n",
    "    ids = encoded_dict['input_ids']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[1:(maxlen//2)] + ids[-(maxlen//2):-1]  + [102]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['input_ids']=torch.tensor([ids])\n",
    "\n",
    "    ids = encoded_dict['attention_mask']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
    "   \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    #print(input_ids)\n",
    "        \n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    decoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "UXBrctLqzvtC"
   },
   "outputs": [],
   "source": [
    "labels=torch.tensor(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "HSSZ0NjsZ853"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                        batch_size=256,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9YJlNfS70W6",
    "outputId": "abf13246-1cde-4538-d6a3-90222fef5308"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "2cxAjuPN70Sf"
   },
   "outputs": [],
   "source": [
    " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
    "   input_ids=input_ids.to(device)\n",
    "   attention_mask=attention_mask.to(device)\n",
    "   labels=labels.to(device)\n",
    "   with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
    "      \n",
    "    if i==0:\n",
    "        last_hidden_states_all = last_hidden_states\n",
    "        labels_all= labels\n",
    "    else:\n",
    "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
    "        labels_all=torch.cat((labels_all,labels),axis=0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kpIbvf170Pi",
    "outputId": "32ea49ec-a110-4224-ea2e-e0d989f7cefd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11314, 768])\n",
      "torch.Size([11314])\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_states_all.shape)\n",
    "print(labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9fzX04970Mp",
    "outputId": "2b4fbf61-ae83-44e0-bb76-cef1a8056220"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 768)"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = last_hidden_states_all.cpu().numpy()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWzaQT9470J1",
    "outputId": "5e771f36-ed0a-4d37-e53a-eeaa17bbbe45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels_all.cpu().numpy()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wyr1m-2L9dQp"
   },
   "source": [
    "**Splitting Teain and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "0XRcnykx70Gm"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6GtzIDc70DR",
    "outputId": "9da01d78-d66f-4a76-9710-fa725ad6b851"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.1}\n",
      "best scrores:  0.6499705362404242\n"
     ]
    }
   ],
   "source": [
    " parameters = {'C': [0.001,0.01,0.1,1]}\n",
    " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
    " grid_search.fit(train_features, train_labels)\n",
    "\n",
    " print('best parameters: ', grid_search.best_params_)\n",
    " print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgsijuHy70Ad",
    "outputId": "3985653e-5967-48cd-b572-b3780671555c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6638388123011665"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c7Qf-UD7z9r"
   },
   "outputs": [],
   "source": [
    "#128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "rXxJRCiX9sAW"
   },
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "decoder_sent=[]\n",
    "before_trunc=[]\n",
    "maxlen=128\n",
    "\n",
    "for sent in df_train.text:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                     \n",
    "                        add_special_tokens = True, \n",
    "                        truncation=False,\n",
    "                        padding=False,           \n",
    "                        return_attention_mask = True\n",
    "                   )\n",
    "   \n",
    "    before_trunc.append(encoded_dict['input_ids'])\n",
    "\n",
    "    ids = encoded_dict['input_ids']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[1:(maxlen//2)] + ids[-(maxlen//2):-1]  + [102]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['input_ids']=torch.tensor([ids])\n",
    "\n",
    "    ids = encoded_dict['attention_mask']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
    "   \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    #print(input_ids)\n",
    "        \n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    decoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "h_FnmqbT9r83"
   },
   "outputs": [],
   "source": [
    "labels=torch.tensor(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "mytAJ8Kh9r5O"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                        batch_size=256,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7UMZ2ixr9r15",
    "outputId": "107195ff-d8bb-4c45-c14f-1600cc992916"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "z8EwAjK29ryA"
   },
   "outputs": [],
   "source": [
    " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
    "   input_ids=input_ids.to(device)\n",
    "   attention_mask=attention_mask.to(device)\n",
    "   labels=labels.to(device)\n",
    "   with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
    "      \n",
    "    if i==0:\n",
    "        last_hidden_states_all = last_hidden_states\n",
    "        labels_all= labels\n",
    "    else:\n",
    "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
    "        labels_all=torch.cat((labels_all,labels),axis=0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4W9qf4L9ruz",
    "outputId": "39765f6c-f413-49c0-fe55-53dbed90a1d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11314, 768])\n",
      "torch.Size([11314])\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_states_all.shape)\n",
    "print(labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLF2mZ879rqr",
    "outputId": "85ee6223-f7fe-40fb-987a-f2b29ac2191f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 768)"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = last_hidden_states_all.cpu().numpy()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ygphSqPh9rmn",
    "outputId": "1c326f70-aea5-4e05-fc32-8ea1a7064d23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 122,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels_all.cpu().numpy()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CoolFm8-iL0"
   },
   "source": [
    "**Splitting train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "bUM1unSy9rj1"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FY10f8hC9rel",
    "outputId": "8efdfbab-2336-4e29-c8a7-215f92ff3a68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.1}\n",
      "best scrores:  0.6289923394225104\n"
     ]
    }
   ],
   "source": [
    " parameters = {'C': [0.001,0.01,0.1,1]}\n",
    " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
    " grid_search.fit(train_features, train_labels)\n",
    "\n",
    " print('best parameters: ', grid_search.best_params_)\n",
    " print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HUdU4W2_Gxg",
    "outputId": "b1ae7e09-f6da-432e-8605-a243969cc522"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6507599858607281"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKYvRUl0_Gui"
   },
   "outputs": [],
   "source": [
    "# 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "KRF_bxCD_GrW"
   },
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "decoder_sent=[]\n",
    "before_trunc=[]\n",
    "maxlen=140\n",
    "\n",
    "for sent in df_train.text:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                     \n",
    "                        add_special_tokens = True, \n",
    "                        truncation=False,\n",
    "                        padding=False,           \n",
    "                        return_attention_mask = True\n",
    "                   )\n",
    "   \n",
    "    before_trunc.append(encoded_dict['input_ids'])\n",
    "\n",
    "    ids = encoded_dict['input_ids']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[1:(maxlen//2)] + ids[-(maxlen//2):-1]  + [102]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['input_ids']=torch.tensor([ids])\n",
    "\n",
    "    ids = encoded_dict['attention_mask']\n",
    "    if len(ids)>=maxlen:\n",
    "      ids = [ids[0]] + ids[-(maxlen-1):-1] + [1]\n",
    "    else:\n",
    "      ids = ids + ([0] * (maxlen-len(ids)))\n",
    "    encoded_dict['attention_mask']=torch.tensor([ids])\n",
    "   \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    #print(input_ids)\n",
    "        \n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    decoder_sent.append(tokenizer.decode(encoded_dict['input_ids'].squeeze()))\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "TRt3Y10H_Gnd"
   },
   "outputs": [],
   "source": [
    "labels=torch.tensor(df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "gPnsejcr_GkZ"
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "data_loader= torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                        batch_size=256,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BThgwc5c_GhR",
    "outputId": "9f0c5555-d28e-4a0f-ee59-3afe310db21c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.to_dict()['hidden_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "DeRx1xqn_GdZ"
   },
   "outputs": [],
   "source": [
    " for i, (input_ids,attention_mask, labels) in enumerate(data_loader):\n",
    "   input_ids=input_ids.to(device)\n",
    "   attention_mask=attention_mask.to(device)\n",
    "   labels=labels.to(device)\n",
    "   with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)[0][:,0,:]\n",
    "      \n",
    "    if i==0:\n",
    "        last_hidden_states_all = last_hidden_states\n",
    "        labels_all= labels\n",
    "    else:\n",
    "        last_hidden_states_all=torch.cat((last_hidden_states_all,last_hidden_states),axis=0)\n",
    "        labels_all=torch.cat((labels_all,labels),axis=0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cs1xk33c_GZc",
    "outputId": "e53f5b56-bc36-4092-b500-cbe768c940c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11314, 768])\n",
      "torch.Size([11314])\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_states_all.shape)\n",
    "print(labels_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DVWmN9K_GUa",
    "outputId": "fcd22489-1ae5-411a-e288-0599b796ae38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 768)"
      ]
     },
     "execution_count": 132,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = last_hidden_states_all.cpu().numpy()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cqjhRSN_GPE",
    "outputId": "bb068eb8-6c9d-40b9-f944-c8b76fdc5060"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels_all.cpu().numpy()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDXnMAOq_opq"
   },
   "source": [
    "**Splitting Train and Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "kGEWKyNH_GGV"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8foRSxZJ_GCA",
    "outputId": "cec2bae4-0c24-4502-8592-21cedb31945e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.1}\n",
      "best scrores:  0.6366529169121979\n"
     ]
    }
   ],
   "source": [
    " parameters = {'C': [0.001,0.01,0.1,1]}\n",
    " grid_search = GridSearchCV(LogisticRegression(max_iter=10000), parameters)\n",
    " grid_search.fit(train_features, train_labels)\n",
    "\n",
    " print('best parameters: ', grid_search.best_params_)\n",
    " print('best scrores: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIr2EC-p_39B",
    "outputId": "dcbeba18-291a-4506-a859-f245b06a6c0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6433368681512902"
      ]
     },
     "execution_count": 136,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIMwYoysHfXt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLEBLW-vHfUu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M6JCz51kHfI_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Experiment_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08c203665d564f5484aff36928672cad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1694fc120faa4a30860733d5b0ca8533": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3eedd8bb2d854cf388946a1fc0d63577",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aab857b501084bf488961ccf31924bee",
      "value": 231508
     }
    },
    "19d4206ea1df44e7954c92d7c648324a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ff16d02cd5a49c494ec6d25bb33dd1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a089271081b4497862c48550e0c516c",
      "placeholder": "​",
      "style": "IPY_MODEL_9f3d0086e0534ffd8412795996d75f5b",
      "value": " 440M/440M [00:07&lt;00:00, 62.4MB/s]"
     }
    },
    "376bf49ee5ad41ddb8cf28e679179210": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_85b1e13a986b4a81ae39ede39c326719",
       "IPY_MODEL_2ff16d02cd5a49c494ec6d25bb33dd1c"
      ],
      "layout": "IPY_MODEL_ada1ba9c9b38401da7bbef43046962bc"
     }
    },
    "3eedd8bb2d854cf388946a1fc0d63577": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4367fa1db43445aea120b5a1fcee4f2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_457256a41d4f4380acd38eb90f9e311a",
      "placeholder": "​",
      "style": "IPY_MODEL_5dcf3052e7c34415bf04c6e4d7b8ac29",
      "value": " 433/433 [00:00&lt;00:00, 3.82kB/s]"
     }
    },
    "457256a41d4f4380acd38eb90f9e311a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5dcf3052e7c34415bf04c6e4d7b8ac29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "794babb404914bd199182f8215637674": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85b1e13a986b4a81ae39ede39c326719": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_794babb404914bd199182f8215637674",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e1d6fc436e6a43c4a8d5976463d9bd1d",
      "value": 440473133
     }
    },
    "8b6dd75fb9444bd7ad88d6910e4b4bd4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a089271081b4497862c48550e0c516c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f3d0086e0534ffd8412795996d75f5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a681dc57ca744c5bb424e4488d07c889": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1694fc120faa4a30860733d5b0ca8533",
       "IPY_MODEL_d6a6c9ff713348d9a813fbd4f0cbc3df"
      ],
      "layout": "IPY_MODEL_8b6dd75fb9444bd7ad88d6910e4b4bd4"
     }
    },
    "aab857b501084bf488961ccf31924bee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ac07937a5185429d842716f37a780347": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ada1ba9c9b38401da7bbef43046962bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b618944566424a6e9f3d5dd229a06845": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8724715e9a3449dae16956c0be83bfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08c203665d564f5484aff36928672cad",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ac07937a5185429d842716f37a780347",
      "value": 433
     }
    },
    "d6a6c9ff713348d9a813fbd4f0cbc3df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f07be0e793c4447aba164b6ca1112af5",
      "placeholder": "​",
      "style": "IPY_MODEL_b618944566424a6e9f3d5dd229a06845",
      "value": " 232k/232k [00:00&lt;00:00, 3.07MB/s]"
     }
    },
    "e1d6fc436e6a43c4a8d5976463d9bd1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f07be0e793c4447aba164b6ca1112af5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f990b63899de4008b7c80fb8f8edf674": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c8724715e9a3449dae16956c0be83bfb",
       "IPY_MODEL_4367fa1db43445aea120b5a1fcee4f2a"
      ],
      "layout": "IPY_MODEL_19d4206ea1df44e7954c92d7c648324a"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
